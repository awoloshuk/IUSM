{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules loaded\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from trainer import Trainer\n",
    "from utils import Logger\n",
    "print(\"Modules loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function gets the parameters from the config.json file \n",
    "def get_instance(module, name, config, *args):\n",
    "    return getattr(module, config[name]['type'])(*args, **config[name]['args'])\n",
    "\n",
    "def main2(config, resume):\n",
    "    # setup data_loader instances\n",
    "    data_loader = getattr(module_data, config['data_loader']['type'])(\n",
    "        config['data_loader']['args']['data_dir'],\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        validation_split=0.0,\n",
    "        training=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    # build model architecture\n",
    "    model = get_instance(module_arch, 'arch', config)\n",
    "    print(model)\n",
    "    if torch.cuda.is_available():\n",
    "        print(torch.cuda.get_device_name(0))   \n",
    "    else:\n",
    "        print(\"using CPU\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # get function handles of loss and metrics\n",
    "    loss_fn = getattr(module_loss, config['loss'])\n",
    "    metric_fns = [getattr(module_metric, met) for met in config['metrics']]\n",
    "    \n",
    "    # load state dict\n",
    "    checkpoint = torch.load(resume, map_location='cpu')\n",
    "    state_dict = checkpoint['state_dict'] #dictionary of model parameters from saved file\n",
    "    if config['n_gpu'] > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.load_state_dict(state_dict) \n",
    "    \n",
    "    \n",
    "    # prepare model for testing\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval() #tells model to ignore dropout and batch normalization\n",
    "    \n",
    "    \n",
    "    heatmap(model, data_loader)\n",
    "    \n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_metrics = torch.zeros(len(metric_fns))\n",
    "    \n",
    "    with torch.no_grad(): #speed up calculations, unable to perform back propogation\n",
    "        for i, (data, target) in enumerate(tqdm(data_loader)): #tqdm is a progress bar\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            #\n",
    "            # save sample images, or do something with output here\n",
    "            #\n",
    "            \n",
    "            \n",
    "            if i < 5:\n",
    "                fig = plt.figure()\n",
    "                output_cpu = output.to(torch.device(\"cpu\"))\n",
    "                plt.title(\"Prediction = \" + str(np.argmax(output_cpu[1], axis=0)))\n",
    "                data_cpu = data.to(torch.device(\"cpu\"))\n",
    "                plt.imshow(data_cpu[1].view([28,28]))\n",
    "                \n",
    "            # computing loss, metrics on test set\n",
    "            loss = loss_fn(output, target)\n",
    "            batch_size = data.shape[0]\n",
    "            total_loss += loss.item() * batch_size\n",
    "            for i, metric in enumerate(metric_fns):\n",
    "                total_metrics[i] += metric(output, target) * batch_size\n",
    "        \n",
    "        plt.show()\n",
    "                      \n",
    "    n_samples = len(data_loader.sampler)\n",
    "    print(\"num samples = \" + str(n_samples))\n",
    "    log = {'loss': total_loss / n_samples}\n",
    "    log.update({met.__name__: total_metrics[i].item() / n_samples for i, met in enumerate(metric_fns)})\n",
    "    print(log)\n",
    "    print(\"My_metric is accuracy, my_metric2 is top-3 accuracy\")\n",
    "    \n",
    "    \n",
    "def heatmap(model, dataloader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    preds = model(images)\n",
    "    def hook_feature(module, inp, outp):\n",
    "        features_blobs.append(outp.data.cpu().numpy())\n",
    "        \n",
    "    for image in images:\n",
    "        layer_names = list(model._modules.keys())\n",
    "        last_layer = layer_names[len(layer_names)-1]\n",
    "        final_layer = model._modules.get(last_layer)\n",
    "        features_blobs = []\n",
    "        model._modules.get(final_layer).register_forward_hook(hook_feature)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "resume = \"saved/Mnist_LeNet/0414_203632/model_best.pth\"\n",
    "\n",
    "print(os.path.isdir(\"saved/Mnist_LeNet/0414_203632\"))\n",
    "print(os.path.exists(resume))\n",
    "\n",
    "#config = torch.load(\"saved/Mnist_LeNet/0414_203632/config.json\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "config_file = 'config.json'\n",
    "# load config file\n",
    "with open(config_file) as handle:\n",
    "    config = json.load(handle)\n",
    "# setting path to save trained models and log files\n",
    "path = os.path.join(config['trainer']['save_dir'], config['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistModel(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "Trainable parameters: 21840\n",
      "using CPU\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'register_forward_hook'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e65738ef7619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-0768789dfbe1>\u001b[0m in \u001b[0;36mmain2\u001b[0;34m(config, resume)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0768789dfbe1>\u001b[0m in \u001b[0;36mheatmap\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfinal_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mfeatures_blobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'register_forward_hook'"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "main2(config, resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
