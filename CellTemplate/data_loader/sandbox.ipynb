{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image, ImageEnhance\n",
    "import h5py\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\awoloshu\\\\Documents\\\\IMPRS\\\\datasets\\\\F44_062419\\\\allDAPI_volume\\\\mydata_test.h5\"\n",
    "\n",
    "def traverse_datasets(hdf_file):\n",
    "\n",
    "    def h5py_dataset_iterator(g, prefix=''):\n",
    "        for key in g.keys():\n",
    "            item = g[key]\n",
    "            path = f'{prefix}/{key}'\n",
    "            if isinstance(item, h5py.Dataset): # test for dataset\n",
    "                yield (path, item)\n",
    "            elif isinstance(item, h5py.Group): # test for group (go down)\n",
    "                yield from h5py_dataset_iterator(item, path)\n",
    "\n",
    "    with h5py.File(hdf_file, 'r') as f:\n",
    "        for path, _ in h5py_dataset_iterator(f):\n",
    "            yield path\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /train_data/_i_table/index/abounds\n",
      "Shape: (0,)\n",
      "Data type: int64\n",
      "Path: /train_data/_i_table/index/bounds\n",
      "Shape: (0, 127)\n",
      "Data type: int64\n",
      "Path: /train_data/_i_table/index/indices\n",
      "Shape: (0, 131072)\n",
      "Data type: uint32\n",
      "Path: /train_data/_i_table/index/indicesLR\n",
      "Shape: (131072,)\n",
      "Data type: uint32\n",
      "Path: /train_data/_i_table/index/mbounds\n",
      "Shape: (0,)\n",
      "Data type: int64\n",
      "Path: /train_data/_i_table/index/mranges\n",
      "Shape: (0,)\n",
      "Data type: int64\n",
      "Path: /train_data/_i_table/index/ranges\n",
      "Shape: (0, 2)\n",
      "Data type: int64\n",
      "Path: /train_data/_i_table/index/sorted\n",
      "Shape: (0, 131072)\n",
      "Data type: int64\n",
      "Path: /train_data/_i_table/index/sortedLR\n",
      "Shape: (131201,)\n",
      "Data type: int64\n",
      "Path: /train_data/_i_table/index/zbounds\n",
      "Shape: (0,)\n",
      "Data type: int64\n",
      "Path: /train_data/table\n",
      "Shape: (216,)\n",
      "Data type: [('index', '<i8'), ('values_block_0', '<i8', (7168,)), ('values_block_1', '<f8', (1,))]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(path, 'r') as f:\n",
    "    for dset in traverse_datasets(path):\n",
    "        print('Path:', dset)\n",
    "        print('Shape:', f[dset].shape)\n",
    "        print('Data type:', f[dset].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awoloshu\\Documents\\IMPRS\\datasets\\F44_062419\\allDAPI_volume\\mydata.h5 (File) ''\n",
      "Last modif.: 'Mon Jun 24 16:44:57 2019'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/test_data (Group) ''\n",
      "/test_data/table (Table(38,)) ''\n",
      "/test_labels (Group) ''\n",
      "/test_labels/table (Table(38,)) ''\n",
      "/train_data (Group) ''\n",
      "/train_data/table (Table(216,)) ''\n",
      "/train_labels (Group) ''\n",
      "/train_labels/table (Table(216,)) ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h5file = tables.open_file(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_data', 'test_labels', 'train_data', 'train_labels']\n",
      "(216,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with h5py.File(path, 'r') as f:\n",
    "    keys = list(f.keys())\n",
    "    print(keys)\n",
    "    data = f['train_data/table'][:]\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151    3\n",
      "35     3\n",
      "235    3\n",
      "20     3\n",
      "218    3\n",
      "55     3\n",
      "205    3\n",
      "27     3\n",
      "24     3\n",
      "7      3\n",
      "122    3\n",
      "67     3\n",
      "71     3\n",
      "225    3\n",
      "57     3\n",
      "254    3\n",
      "72     3\n",
      "76     3\n",
      "74     3\n",
      "90     3\n",
      "232    3\n",
      "171    3\n",
      "28     3\n",
      "198    3\n",
      "202    3\n",
      "134    3\n",
      "46     3\n",
      "103    3\n",
      "8      3\n",
      "50     3\n",
      "      ..\n",
      "79     3\n",
      "81     3\n",
      "213    3\n",
      "150    3\n",
      "54     3\n",
      "212    3\n",
      "211    3\n",
      "152    3\n",
      "240    3\n",
      "204    3\n",
      "209    3\n",
      "143    3\n",
      "48     3\n",
      "199    3\n",
      "214    3\n",
      "253    3\n",
      "183    3\n",
      "100    3\n",
      "250    3\n",
      "145    3\n",
      "30     3\n",
      "26     3\n",
      "121    3\n",
      "234    3\n",
      "160    3\n",
      "29     3\n",
      "187    3\n",
      "123    3\n",
      "146    3\n",
      "92     3\n",
      "Length: 216, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_hdf(path, 'train_labels')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/test_data', '/test_labels', '/train_data', '/train_labels']\n",
      "2705\n"
     ]
    }
   ],
   "source": [
    "st = pd.HDFStore(path)\n",
    "print(st.keys())\n",
    "#print(st['train_data'])\n",
    "td = st['train_data'].values\n",
    "print(td.shape[0])\n",
    "st.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
